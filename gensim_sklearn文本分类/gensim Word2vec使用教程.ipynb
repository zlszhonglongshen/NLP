{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnson\\Anaconda3\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2018-07-08 18:51:12,326 : INFO : collecting all words and their counts\n",
      "2018-07-08 18:51:12,327 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-07-08 18:51:12,328 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2018-07-08 18:51:12,330 : INFO : Loading a fresh vocabulary\n",
      "2018-07-08 18:51:12,331 : INFO : effective_min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2018-07-08 18:51:12,332 : INFO : effective_min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2018-07-08 18:51:12,334 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2018-07-08 18:51:12,336 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2018-07-08 18:51:12,338 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2018-07-08 18:51:12,347 : INFO : estimated required memory for 3 words and 100 dimensions: 3900 bytes\n",
      "2018-07-08 18:51:12,348 : INFO : resetting layer weights\n",
      "2018-07-08 18:51:12,352 : INFO : training model with 3 workers on 3 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-07-08 18:51:12,366 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-08 18:51:12,368 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-08 18:51:12,370 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-08 18:51:12,371 : INFO : EPOCH - 1 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-07-08 18:51:12,389 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-08 18:51:12,390 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-08 18:51:12,393 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-08 18:51:12,394 : INFO : EPOCH - 2 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-07-08 18:51:12,400 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-08 18:51:12,402 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-08 18:51:12,404 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-08 18:51:12,406 : INFO : EPOCH - 3 : training on 4 raw words (1 effective words) took 0.0s, 150 effective words/s\n",
      "2018-07-08 18:51:12,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-08 18:51:12,420 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-08 18:51:12,422 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-08 18:51:12,423 : INFO : EPOCH - 4 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-07-08 18:51:12,429 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-07-08 18:51:12,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-07-08 18:51:12,432 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-07-08 18:51:12,433 : INFO : EPOCH - 5 : training on 4 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2018-07-08 18:51:12,435 : INFO : training on a 20 raw words (1 effective words) took 0.1s, 12 effective words/s\n",
      "2018-07-08 18:51:12,437 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "# import modules & set up logging\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "sentences = [['first', 'sentence'], ['second', 'sentence']]\n",
    "# train word2vec on the two sentences\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self,dirname):\n",
    "        self.dirname = dirname\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname,fname)):\n",
    "                yield line.split()\n",
    "sentences = MySentences('/some/directory')\n",
    "model = gensim.models.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要对文件中的单词做其他处理, 比如转换为unicode, 转换大小写, 删除数字, 抽取命名实体等, 所有这些都可以在MySentence迭代器中进行处理.\n",
    "\n",
    "注意, word2vec会在整个句子序列上跑两遍, 第一遍会收集单词及其词频来够爱走一个内部字典树结构. 第二遍才会训练神经网络. 如果你只能遍历一边数据, 则可以参考以下做法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec() #an empty model, no training\n",
    "model.build_vocab(some_sentences)\n",
    "model.train(oother_sentences)# can be a non-repeatable, 1-pass generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
