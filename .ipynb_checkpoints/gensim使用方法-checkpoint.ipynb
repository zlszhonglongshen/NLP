{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1：corpora和dictionary的基本概念和用法\n",
    "corpora是gensim的一个基本概念，是文档集的表现形式。\n",
    "举例：\n",
    "hurry up\n",
    "rise up\n",
    "这两篇文档里面共有3个词，如果将这3个词映射到数字，比如说hurry, rise, up 分别对应1,2,3， 那么上述的文档集的一种表现形式可以是：\n",
    "1,0,1\n",
    "0,1,1\n",
    "这种方法有一些弊端，比如只考虑了词频，且不考虑词语间的位置关系。因为第一个文档的两个词分别编号1,3且都只出现了一次，所以第1个和第3个为1，第2个为0；但是当文章单词量极多的时候，这种表达方式就不合适了，需要采用稀疏矩阵的形式\n",
    "\n",
    "那么，如果将字符串形式的文档转换为上述形式呢？这里就要提到词典的概念，词典是所有文章中所有单词的集合，而且记录了各词的出现次数等信息。\n",
    "\n",
    "\n",
    "将文档分词分割成词语之后，使用dictionary = corpora.Dictionary(texts)生成词典，并可以使用save函数将词典持久化，生成词典以后corpus=[dictionary.doc2bow(text) for text in texts]转化为向量形式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnson\\Anaconda3\\envs\\py36\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去停用词\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
    "\n",
    "# 去掉只出现一次的单词\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] > 1]\n",
    "         for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts) #生成地点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将文档存入字典，字典有很多功能，比如：\n",
    "# diction.token2id 存放的是单词-id key-value对\n",
    "# diction.dfs 存放的是单词的出现频率\n",
    "\n",
    "# dictionary.save('/tmp/deerwester.dict')\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "# corpora.MmCorpus.serialize('/tmp/deerwester.mm', corpus)  # store to disk, for later use\n",
    "\n",
    "# 注意最后的corpora.MmCorpus.serialize 将corpus持久化到磁盘中。相反，可以用\n",
    "# corpus = corpora.MmCorpus('/tmp/deerwester.mm')\n",
    "# 来读取磁盘中的corpus\n",
    "# 除了MmCorpus以外，还有其他的格式，例如SvmLightCorpus, BleiCorpus, LowCorpus等等，用法类似。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 dictionary的其他一些用法\n",
    "dictionary还有其他的一些用法，现罗列一部分\n",
    "dictionary.filter_n_most_frequent(N) \n",
    "过滤掉出现频率最高的N个单词\n",
    "\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000) \n",
    "1.去掉出现次数低于no_below的 \n",
    "2.去掉出现次数高于no_above的。注意这个小数指的是百分数 \n",
    "3.在1和2的基础上，保留出现频率前keep_n的单词\n",
    "\n",
    "dictionary.filter_tokens(bad_ids=None, good_ids=None) \n",
    "有两种用法，一种是去掉bad_id对应的词，另一种是保留good_id对应的词而去掉其他词。注意这里bad_ids和good_ids都是列表形式\n",
    "\n",
    "dictionary.compacity() \n",
    "在执行完前面的过滤操作以后，可能会造成单词的序号之间有空隙，这时就可以使用该函数来对词典来进行重新排序，去掉这些空隙。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2:models\n",
    "在models中，可以对corpus进行进一步的处理，比如使用tf-idf模型，lda模型等，非常强大\n",
    "在按照之前的方法生成了corpus和dictionary以后，就可以生成模型了\n",
    "    tfidf_model = models.TfidfModel(corpus)\n",
    "    \n",
    "注意，目前只是生成了一个模型，但这是类似与生成器，并不是将对应corpus转换后的结果，对tf-idf模型而言，里面存储有各个单词的词频，文频等信息。想要将文档转换成if-idf模型表示的向量，还要使用一下命令\n",
    "corpus_tfidf = tfidf_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models,similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于lda和lsi模型，用法有所不同\n",
    "\n",
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "corpus_lsi = lsi_model[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，这里除了corpus以外，还多了num_topic的选项。这是指的潜在主题(topic)的数目，也等于转成lsi模型以后每个文档对应的向量长度。转化以后的向量在各项的值，即为该文档在该潜在主题的权重。因此lsi和lda的结果也可以看做该文档的文档向量，用于后续的分类，聚类等算法。值得注意的是，id2word是所有模型都有的选项，可以指定使用的词典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim import corpora, models, similarities\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def PrintDictionary(dictionary):\n",
    "    token2id = dictionary.token2id\n",
    "    dfs = dictionary.dfs\n",
    "    token_info = {}\n",
    "    for word in token2id:\n",
    "        token_info[word] = dict(\n",
    "            word = word,\n",
    "            id = token2id[word],\n",
    "            freq = dfs[token2id[word]]\n",
    "        )\n",
    "    token_items = token_info.values()\n",
    "    token_items = sorted(token_items, key = lambda x:x['id'])\n",
    "    print('The info of dictionary: ')\n",
    "    pprint(token_items)\n",
    "    print('--------------------------')\n",
    "\n",
    "def Show2dCorpora(corpus):\n",
    "    nodes = list(corpus)\n",
    "    ax0 = [x[0][1] for x in nodes] # 绘制各个doc代表的点\n",
    "    ax1 = [x[1][1] for x in nodes]\n",
    "    # print(ax0)\n",
    "    # print(ax1)\n",
    "    plt.plot(ax0,ax1,'o')\n",
    "    plt.show()\n",
    "\n",
    "if (os.path.exists(\"/tmp/deerwester.dict\")):\n",
    "    dictionary = corpora.Dictionary.load('/tmp/deerwester.dict')\n",
    "    corpus = corpora.MmCorpus('/tmp/deerwester.mm')\n",
    "    print(\"Used files generated from first tutorial\")\n",
    "else:\n",
    "    print(\"Please run first tutorial to generate data set\")\n",
    "\n",
    "PrintDictionary(dictionary)\n",
    "\n",
    "# 尝试将corpus(bow形式) 转化成tf-idf形式\n",
    "tfidf_model = models.TfidfModel(corpus) # step 1 -- initialize a model 将文档由按照词频表示 转变为按照tf-idf格式表示\n",
    "doc_bow = [(0, 1), (1, 1),[4,3]]\n",
    "doc_tfidf = tfidf_model[doc_bow]\n",
    "\n",
    "# 将整个corpus转为tf-idf格式\n",
    "corpus_tfidf = tfidf_model[corpus]\n",
    "# pprint(list(corpus_tfidf))\n",
    "# pprint(list(corpus))\n",
    "\n",
    "## LSI模型 **************************************************\n",
    "# 转化为lsi模型, 可用作聚类或分类\n",
    "lsi_model = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "corpus_lsi = lsi_model[corpus_tfidf]\n",
    "nodes = list(corpus_lsi)\n",
    "# pprint(nodes)\n",
    "lsi_model.print_topics(2) # 打印各topic的含义\n",
    "\n",
    "# ax0 = [x[0][1] for x in nodes] # 绘制各个doc代表的点\n",
    "# ax1 = [x[1][1] for x in nodes]\n",
    "# print(ax0)\n",
    "# print(ax1)\n",
    "# plt.plot(ax0,ax1,'o')\n",
    "# plt.show()\n",
    "\n",
    "lsi_model.save('/tmp/model.lsi') # same for tfidf, lda, ...\n",
    "lsi_model = models.LsiModel.load('/tmp/model.lsi')\n",
    "#  *********************************************************\n",
    "\n",
    "## LDA模型 **************************************************\n",
    "lda_model = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "corpus_lda = lda_model[corpus_tfidf]\n",
    "Show2dCorpora(corpus_lsi)\n",
    "# nodes = list(corpus_lda)\n",
    "# pprint(list(corpus_lda))\n",
    "\n",
    "# 此外，还有Random Projections, Hierarchical Dirichlet Process等模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.9991645), (1, 0.9963216), (2, 0.9990505), (3, 0.99886364), (4, 0.99996823), (5, -0.058117405), (6, -0.02158928), (7, 0.0135240555), (8, 0.25163394)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnson\\Anaconda3\\envs\\py36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "corpus_simi_matrix = similarities.MatrixSimilarity(corpus_lsi)\n",
    "# 计算一个新的文本与既有文本的相关度\n",
    "test_text = \"Human computer interaction\".split()\n",
    "test_bow = dictionary.doc2bow(test_text)\n",
    "test_tfidf = tfidf_model[test_bow]\n",
    "test_lsi = lsi_model[test_tfidf]\n",
    "test_simi = corpus_simi_matrix[test_lsi]\n",
    "print(list(enumerate(test_simi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
