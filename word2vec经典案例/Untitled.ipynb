{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold,StratifiedKFold\n",
    "from gensim.models import word2vec\n",
    "import xgboost as xgb\n",
    "import numpy as np \n",
    "from sklearn.linear_model import SGDClassifier,LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = u'G:/NLP/搜狗复赛数据/user_tag_query.10W.TRAIN'\n",
    "csvfile = file(add+'.csv','wb') #\n",
    "writer = csv.writer(csvfile)\n",
    "writer.writerow(['ID', 'age', 'Gender', 'Education', 'QueryList'])\n",
    "with open(add,'r') as f:\n",
    "    for line in f:\n",
    "        line.strip()\n",
    "        data = line.split(\"\\t\")\n",
    "        writedata = [data[0],data[1],data[2],data[3]]\n",
    "        querystr = ''\n",
    "        data[-1] = data[-1][:-1]\n",
    "        for d in data[4:]:\n",
    "           try:\n",
    "                querystr += d.decode('GB18030').encode('utf8') + '\\t'\n",
    "           except:\n",
    "               print (data[0],querystr)\n",
    "        querystr = querystr[:-1]\n",
    "        writedata.append(querystr)\n",
    "        writer.writerow(writedata)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = u'G:/NLP/搜狗复赛数据/user_tag_query.10W.TEST'#path of the original test file\n",
    "\n",
    "csvfile = file(add + '.csv', 'wb')# the path of the generated test file\n",
    "writer = csv.writer(csvfile)\n",
    "writer.writerow(['ID', 'QueryList'])\n",
    "with open(add, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.split(\"\\t\")\n",
    "        writedata = [data[0]]\n",
    "        querystr = ''\n",
    "        data[-1]=data[-1][:-1]\n",
    "        for d in data[1:]:\n",
    "           try:\n",
    "                querystr += d.decode('GB18030').encode('utf8') + '\\t'\n",
    "           except:\n",
    "               print (data[0],querystr)\n",
    "        querystr = querystr[:-1]\n",
    "        writedata.append(querystr)\n",
    "        writer.writerow(writedata) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class w2v():\n",
    "    def __init__(self,size=300):\n",
    "        random_rate = 8240\n",
    "        self.size = size\n",
    "        self.svc = SVC(C=1,random_state=random_rate)\n",
    "        self.LR = LogisticRegression(C=1.0,max_iter=100,class_weight='balanced', random_state=random_rate, n_jobs=-1)\n",
    "        self.clf = LinearSVC(random_state=random_rate)\n",
    "        \n",
    "    def fit(self,X,Y,T):\n",
    "        \"\"\"\n",
    "        train and predict\n",
    "        \"\"\"\n",
    "        print(\"fitting...\")\n",
    "        self.LR.fit(X,Y)\n",
    "        res = self.LR.predict(T)\n",
    "        return res\n",
    "    \n",
    "    def validation(self,X,Y,kind):\n",
    "        \"\"\"\n",
    "        使用2-fold进行验证\n",
    "        \"\"\"\n",
    "        fold_n = 2\n",
    "        folds = list(StratifiedKFold(Y,n_folds=fold_n,random_state=0))\n",
    "        score = np.zeros(fold_n)\n",
    "        for j,(train_idx,test_idx) in enumerate(folds):\n",
    "            print(j+1,'-fold')\n",
    "            X_train = X[train_idx]\n",
    "            y_train = Y[train_idx]\n",
    "            X_test = X[test_idx]\n",
    "            y_test = Y[test_idx]\n",
    "            \n",
    "            res = self.fit(X_train,y_train,X_test)\n",
    "            cur = sum(y_test==res)*1.0/len(res)\n",
    "            score[j] = cur\n",
    "            \n",
    "        print(score,score.mean())\n",
    "        return score.mean()\n",
    "    \n",
    "    def train_w2v(self,filename):\n",
    "        \"\"\"\n",
    "        训练wv模型\n",
    "        \"\"\"\n",
    "        sentences = word2vec.LineSentence(filename) # 加载语料，要求语料为“一行一文本”的格式\n",
    "        print('正在训练w2v针对语料：',str(filename))\n",
    "        print('size is:',self.size)\n",
    "        model = word2vec.Word2Vec(sentences,size=self.size,window=100,workers=48) #训练模型，注意参数window对结果有影响，一般是5-100\n",
    "        savepath = '20w_size_win100_'+str(self.size)+'.model' #保存model\n",
    "        print(\"训练完毕，已经保存：\",savepath)\n",
    "        model.save(savepath)\n",
    "        \n",
    "    def load_transform(self,X):\n",
    "        \"\"\"\n",
    "        载入模型，并且声称wv向量\n",
    "        \"\"\"\n",
    "        print('载入模型中')\n",
    "        model = word2vec.Word2Vec.load('20w_size_win100_300.model') #填入自己的路径\n",
    "#         print{\"载入成功\"}\n",
    "        res = np.zeros((len(X),self.size))\n",
    "        for i,line in enumerate(X):\n",
    "            line = line.decode('utf-8')\n",
    "            terms = line.split()\n",
    "            count = 0\n",
    "            for j,term in enumerate(terms):\n",
    "                try: #try失败说明X中有单词不在model，训练的时候model的模型是min_count的，忽略了一部分单词\n",
    "                    count+=1\n",
    "                    res[i]+=np.asarray(model[term])\n",
    "                except:\n",
    "                    1 == 1\n",
    "            if count!=0:\n",
    "                res[i] = res[i]/float(count) #求均值\n",
    "        return res\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class preprocess():\n",
    "    # 主要功能：去除缺失值\n",
    "    def removezero(self, x, y):\n",
    "        nozero = np.nonzero(y)\n",
    "        y = y[nozero]\n",
    "        x = np.array(x)\n",
    "        x = x[nozero]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input(trainname):\n",
    "    \"\"\"\n",
    "    load file\n",
    "    \"\"\"\n",
    "    traindata = []\n",
    "    with open(trainname,'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        count = 0\n",
    "        for line in reader:\n",
    "            try:\n",
    "                traindata.append(line[0])\n",
    "                count+=1\n",
    "            except:\n",
    "                print(\"error:\",line,count)\n",
    "                traindata.append(\" \")\n",
    "    return traindata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==='__main__':\n",
    "    \"\"\"\n",
    "    使用方法：先讯洗洗脸wv的model，然后在生成wv的向量，最后可以使用2-fold验证\n",
    "    主要目的：生成wv向量，提供给下一个步骤，特征融合\n",
    "    注意路径\n",
    "    \"\"\"\n",
    "    print(\"------w2v-----\")\n",
    "    order = 'test'\n",
    "    classob = w2v(300)\n",
    "    \n",
    "    if order==\"train w2v model\": #训练wv的model\n",
    "        totalname = 'jieba_total_cut.csv' #纯文本文件路径\n",
    "        classod.train_w2v(totalname)\n",
    "        exit()\n",
    "    elif order=='getvec': #利用生成的model得到文档的WV的向量，使用求和平均法\n",
    "        trainname = 'jieba_train_cut.csv'\n",
    "        testname = 'jieba_test_cut.csv'\n",
    "        traindata = input(trainname)\n",
    "        testdata = input(testname)\n",
    "        res1 = classob.load_trainsform(traindata)\n",
    "        res2 = classob.load_trainsform(testdata)\n",
    "        np.save()\n",
    "        print(res1.shape,res2.shape)\n",
    "        np.save('wv300_win100.train.npy', res1)#保存生成的向量\n",
    "        np.save('wv300_win100.test.npy', res2)\n",
    "        exit()\n",
    "        \n",
    "    #以下为测试WV向量，即仅仅使用WV向量做这个比赛，目的在与寻找好的参数的WV向量\n",
    "    print '载入所有的w2v向量中..'\n",
    "    w2vtrain = np.load('wv300_win100.train.npy')\n",
    "    w2vtest = np.load('wv300_win100.test.npy')\n",
    "\n",
    "    #防止出现非法值\n",
    "    if np.any((np.isnan(w2vtrain))):\n",
    "        print 'nan to num!'\n",
    "        w2vtrain = np.nan_to_num(w2vtrain)\n",
    "\n",
    "    if np.any((np.isnan(w2vtest))):\n",
    "        print 'nan to num!'\n",
    "        w2vtest = np.nan_to_num(w2vtest)\n",
    "\n",
    "    #载入label文件\n",
    "    label_genderfile_path = 'train_gender.csv'\n",
    "    label_agefile_path = 'train_age.csv'\n",
    "    label_edufile_path = 'train_education.csv'\n",
    "    genderdata = np.loadtxt(open(label_genderfile_path, 'r')).astype(int)\n",
    "    agedata = np.loadtxt(open(label_agefile_path, 'r')).astype(int)\n",
    "    educationdata = np.loadtxt(open(label_edufile_path, 'r')).astype(int)\n",
    "\n",
    "    print '预处理中..'\n",
    "    preprocessob = preprocess.preprocess()\n",
    "    gender_traindatas, genderlabel = preprocessob.removezero(w2vtrain, genderdata)\n",
    "    age_traindatas, agelabel = preprocessob.removezero(w2vtrain, agedata)\n",
    "    edu_traindatas, edulabel = preprocessob.removezero(w2vtrain, educationdata)\n",
    "    # ------------------------------------------------------\n",
    "\n",
    "    if order == 'test': #使用2-fold进行验证\n",
    "        res1 = classob.validation(gender_traindatas, genderlabel, kind='gender')\n",
    "        res2 = classob.validation(age_traindatas, agelabel, kind='age')\n",
    "        res3 = classob.validation(edu_traindatas, edulabel, kind='edu')\n",
    "        print 'avg is:', (res1+res2+res3)/3.0\n",
    "    else:\n",
    "        print 'error!'\n",
    "        exit()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'Queue'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7d80cfc3a21e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mQueue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mSTFIWF\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'Queue'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import multiprocessing,Queue\n",
    "from sklearn.cross_validation import KFold, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "from STFIWF import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression,RidgeClassifier,PassiveAggressiveClassifier,Lasso,HuberRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.ensemble import VotingClassifier,RandomForestClassifier,gradient_boosting\n",
    "from sklearn.ensemble.bagging import BaggingClassifier\n",
    "from sklearn.ensemble.weight_boosting import AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
