{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = open('msr_train.txt').read()\n",
    "# .decode('gbk')\n",
    "s = s.split('\\r\\n')\n",
    "\n",
    "def clean(s): #整理一下数据，有些不规范的地方\n",
    "    if u'“/s'  in s:\n",
    "        return s.replace(u' ”/s', '')\n",
    "    elif u'”/s'  in s:\n",
    "        return s.replace(u'“/s ', '')\n",
    "    elif u'‘/s'  in s:\n",
    "        return s.replace(u' ’/s', '')\n",
    "    elif u'’/s'  in s:\n",
    "        return s.replace(u'‘/s ', '')\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "s = u''.join(map(clean, s))\n",
    "s = re.split(u'[，。！？、]/[bems]', s)\n",
    "\n",
    "data = [] #生成训练样本\n",
    "label = []\n",
    "def get_xy(s):\n",
    "    s = re.findall('(.)/(.)', s)\n",
    "    if s:\n",
    "        s = np.array(s)\n",
    "        return list(s[:,0]), list(s[:,1])\n",
    "\n",
    "for i in s:\n",
    "    x = get_xy(i)\n",
    "    if x:\n",
    "        data.append(x[0])\n",
    "        label.append(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 32\n",
    "d = pd.DataFrame(index=range(len(data)))\n",
    "d['data'] = data\n",
    "d['label'] = label\n",
    "d = d[d['data'].apply(len)<=maxlen]\n",
    "d.index = range(len(d))\n",
    "tag = pd.Series({'s':0, 'b':1, 'm':2, 'e':3, 'x':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[“, 人, 们, 常, 说, 生, 活, 是, 一, 部, 教, 科, 书]</td>\n",
       "      <td>[s, b, e, s, s, b, e, s, s, s, b, m, e]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[而, 血, 与, 火, 的, 战, 争, 更, 是, 不, 可, 多, 得, 的, 教, ...</td>\n",
       "      <td>[s, s, s, s, s, b, e, s, s, b, m, m, e, s, b, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[她, 确, 实, 是, 名, 副, 其, 实, 的, ‘, 我, 的, 大, 学, ’]</td>\n",
       "      <td>[s, b, e, s, b, m, m, e, s, s, s, s, b, e, s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[“, 心, 静, 渐, 知, 春, 似, 海]</td>\n",
       "      <td>[s, s, s, s, s, s, s, s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[花, 深, 每, 觉, 影, 生, 香]</td>\n",
       "      <td>[s, s, s, s, s, s, s]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0            [“, 人, 们, 常, 说, 生, 活, 是, 一, 部, 教, 科, 书]   \n",
       "1  [而, 血, 与, 火, 的, 战, 争, 更, 是, 不, 可, 多, 得, 的, 教, ...   \n",
       "2      [她, 确, 实, 是, 名, 副, 其, 实, 的, ‘, 我, 的, 大, 学, ’]   \n",
       "3                           [“, 心, 静, 渐, 知, 春, 似, 海]   \n",
       "4                              [花, 深, 每, 觉, 影, 生, 香]   \n",
       "\n",
       "                                               label  \n",
       "0            [s, b, e, s, s, b, e, s, s, s, b, m, e]  \n",
       "1  [s, s, s, s, s, b, e, s, s, b, m, m, e, s, b, ...  \n",
       "2      [s, b, e, s, b, m, m, e, s, s, s, s, b, e, s]  \n",
       "3                           [s, s, s, s, s, s, s, s]  \n",
       "4                              [s, s, s, s, s, s, s]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [] #统计所有字，跟每个字编号\n",
    "for i in data:\n",
    "    chars.append(i)\n",
    "    \n",
    "\n",
    "chars = pd.Series(chars).value_counts()\n",
    "chars[:] = range(1,len(chars)+1)\n",
    "\n",
    "#生成合适模型输入的格式\n",
    "from keras.utils import np_utils\n",
    "d['x'] = d['data'].apply(lambda x:np.array(list(chars[x])+[0]*(maxlen-len(x))))\n",
    "\n",
    "def trans_one(x):\n",
    "    _ = map(lambda x:np_utils.to_categorical(y,5),tag[x].reshape((-1,1)))\n",
    "    _ = list(_)\n",
    "    _.extend([np.array([[0,0,0,0,1]])]*(maxlen-len(x)))\n",
    "    return np.array(_)\n",
    "\n",
    "d['y'] = d['label'].apply(trans_one)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设计模型\n",
    "word_size = 128\n",
    "from keras.layers import Dense, Embedding, LSTM, TimeDistributed, Input, Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "sequence = Input(shape=(maxlen,), dtype='int32')\n",
    "embedded = Embedding(len(chars)+1, word_size, input_length=maxlen, mask_zero=True)(sequence)\n",
    "blstm = Bidirectional(LSTM(64, return_sequences=True), merge_mode='sum')(embedded)\n",
    "output = TimeDistributed(Dense(5, activation='softmax'))(blstm)\n",
    "model = Model(input=sequence, output=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 1024\n",
    "history = model.fit(np.array(list(d['x'])), np.array(list(d['y'])).reshape((-1,maxlen,5)), batch_size=batch_size, nb_epoch=50)\n",
    "\n",
    "\n",
    "#转移概率，单纯用了等概率\n",
    "zy = {'be':0.5, \n",
    "      'bm':0.5, \n",
    "      'eb':0.5, \n",
    "      'es':0.5, \n",
    "      'me':0.5, \n",
    "      'mm':0.5,\n",
    "      'sb':0.5, \n",
    "      'ss':0.5\n",
    "     }\n",
    "zy = {i:np.log(zy[i]) for i in zy.keys()}\n",
    "\n",
    "def viterbi(nodes):\n",
    "    paths = {'b':nodes[0]['b'], 's':nodes[0]['s']}\n",
    "    for l in range(1,len(nodes)):\n",
    "        paths_ = paths.copy()\n",
    "        paths = {}\n",
    "        for i in nodes[l].keys():\n",
    "            nows = {}\n",
    "            for j in paths_.keys():\n",
    "                if j[-1]+i in zy.keys():\n",
    "                    nows[j+i]= paths_[j]+nodes[l][i]+zy[j[-1]+i]\n",
    "            k = np.argmax(nows.values())\n",
    "            paths[nows.keys()[k]] = nows.values()[k]\n",
    "    return paths.keys()[np.argmax(paths.values())]\n",
    "\n",
    "def simple_cut(s):\n",
    "    if s:\n",
    "        r = model.predict(np.array([list(chars[list(s)].fillna(0).astype(int))+[0]*(maxlen-len(s))]), verbose=False)[0][:len(s)]\n",
    "        r = np.log(r)\n",
    "        nodes = [dict(zip(['s','b','m','e'], i[:4])) for i in r]\n",
    "        t = viterbi(nodes)\n",
    "        words = []\n",
    "        for i in range(len(s)):\n",
    "            if t[i] in ['s', 'b']:\n",
    "                words.append(s[i])\n",
    "            else:\n",
    "                words[-1] += s[i]\n",
    "        return words\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "not_cuts = re.compile(u'([\\da-zA-Z ]+)|[。，、？！\\.\\?,!]')\n",
    "def cut_word(s):\n",
    "    result = []\n",
    "    j = 0\n",
    "    for i in not_cuts.finditer(s):\n",
    "        result.extend(simple_cut(s[j:i.start()]))\n",
    "        result.append(s[i.start():i.end()])\n",
    "        j = i.end()\n",
    "    result.extend(simple_cut(s[j:]))\n",
    "    return result\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
